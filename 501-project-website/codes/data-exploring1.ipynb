{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Exploring Data\"\n",
    "format: \n",
    "    html:\n",
    "        code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis(EDA)\n",
    "Exploratory data analysis is an useful approach to analyze and visualize the data. Analysts can use EDA to find trends, gather summary of statistics, and make a representation of graphics. \n",
    "\n",
    "In my project, I plan to use the data I cleaned previously to do EDA in order to gather some summaries of datasets. \n",
    "\n",
    "For twitter dataset I gathered from python, I plan to make visualizations of frequencies of words in order to get a first insight of attitudes of consumers. I plan to make a histogram of top 20 words with the highest frequencies and make a wordcloud of the bag of words. From these plots, you can find the most frequent words directly and have the first assumptions of consumers' attitudes. \n",
    "\n",
    "For twitter dataset I gathered from R, I also plan to make visualizations of frequencies of words to calculate he social platform popularities. More than this, It can also provide feedbacks about the consumers revies of each social platforms. \n",
    "\n",
    "For Modified data, I have two datasets which are instagram influencers dataset and advertising dataset. I will first explore the variables and understand what each variables mean then deeper make a visualization in order to gather some useful information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Twitter API in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, three datasets are being used: word frequency dataset (wordfreqpython.csv), sentiment scorre dataset(pytweetscore.csv) and sentiment result dataset(pytweetresult.csv)\n",
    "\n",
    "First, I want to gather the histogram of word of frequencies to take a first glimpse of the result. \n",
    "\n",
    "Next, the wordcloud of the frequencies can bring us a lot of information of the consumers' attitudes. \n",
    "\n",
    "I will also calculate the distribution of attitudes(neg,pos,neu) in order to summary the components of consumers' attitudes about social platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this dataframe, \n",
    "\n",
    "\n",
    "words: name of the count words\n",
    "\n",
    "\n",
    "counts: frequencies that each word appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>zfnumberifvzdbnumber</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>519</td>\n",
       "      <td>zero</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>546</td>\n",
       "      <td>year</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>344</td>\n",
       "      <td>xpipnumberunumbergm</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366</td>\n",
       "      <td>wsbchairman</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 words  counts\n",
       "0          52  zfnumberifvzdbnumber     616\n",
       "1         519                  zero     615\n",
       "2         546                  year     614\n",
       "3         344   xpipnumberunumbergm     613\n",
       "4         366           wsbchairman     612"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetfreq = pd.read_csv(\"../data/01-modified-data/wordfreqpython.csv\")\n",
    "tweetfreq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('anly580')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6703eaa97a7816f86f7fd910e66f7a7d435937003aa3ee942d4c5cd77cb9ad5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
