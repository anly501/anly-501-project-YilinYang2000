<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.649">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>SVM for text data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="SVM_files/libs/clipboard/clipboard.min.js"></script>
<script src="SVM_files/libs/quarto-html/quarto.js"></script>
<script src="SVM_files/libs/quarto-html/popper.min.js"></script>
<script src="SVM_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="SVM_files/libs/quarto-html/anchor.min.js"></script>
<link href="SVM_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="SVM_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="SVM_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="SVM_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="SVM_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">SVM for text data</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ol type="1">
<li><p>Dataset Introduction</p>
<p>This dataset contains text I collected from twitter api. The text mainly talks about the users’ reviews about consumers privacy by using media. Then I use sentiment analysis to determine the users’ attitudes (Neutral, Positive, Negaitve) and assign a attitude socres about their texts. There are 1299 rows and 4 columns in this dataset.</p>
<pre><code> Unnamed: 0 : The number id of each content

 text: Each review from twitter users

 result: Sentiment classification of each text(Positive, Neutral, Negative)

 scores: Attitude scores. How likely the attitude to be Neutral, Postive, Negative</code></pre></li>
<li><p>Methods I plan to use</p>
<p>Support Vector Machine</p>
<p>Support Vector Machine (SVM) is a kind of generalized linear classifier ​​that performs binary classification on data according to supervised learning, and its decision boundary is the maximum margin for solving the learning samples Hyperplane (maximum-margin hyperplane).</p>
<p>SVM uses the hinge loss function (hinge loss) to calculate the empirical risk and adds a regularization term to the solution system to optimize the structural risk (structural risk). It is a sparse and robust classifier. SVM can perform nonlinear classification through the kernel method, which is one of the common kernel learning methods</p>
<p>Linearly Separable SVM When the training data is linearly separable, a linear classifier can be learned by maximizing the hard margin (hard margin, what is hard and soft margin will be discussed below), that is, hard margin SVM, such as H3 in the above figure. Linear SVM When the training data is not linearly separable but can be approximately linearly separable, a linear classifier can also be learned by maximizing the soft margin, that is, soft margin SVM. Nonlinear SVM When the training data is linearly inseparable, a non-linear SVM can be learned by using the kernel trick and soft margin maximization.</p></li>
<li><p>Steps</p></li>
</ol>
<p>Import datasets</p>
<pre><code>    Drop unnecessary columns from the dataset(From this dataset, I mainly use text and result columns)</code></pre>
<p>Basic data exploration</p>
<pre><code>Make some necessary EDA plots to get some first insight of the dataset. 

I will use y = "result" (output_score) and "text" as feature. 

Then I will reprocess the column text (Important!)

        1. Drop NA
        2. Change all letters to lower case
        3. Broke the sentence into words
        4. Remove stopwords</code></pre>
<p>Split Dataset</p>
<pre><code>    I will split dataset into 80% training data and 20% test data to get better prediction for SVM</code></pre>
<p>Training the model and Testing the results</p>
<pre><code>    Use x_train,y_train to build a model of SVM

    Evaluate the performance of the SVM model by using the test data. 
        
        Train different kernel in order to get the best performance of model

        Generate a confusion matrix plot for SVM model to evaluate the performance</code></pre>
<p>Conclusion</p>
<pre><code>    Gather the result of the SVM performance</code></pre>
<section id="step-1-import-dataset" class="level4">
<h4 class="anchored" data-anchor-id="step-1-import-dataset">Step 1 Import Dataset</h4>
<section id="read-dataset-in-pd.read_csv-and-display-first-several-rows." class="level5">
<h5 class="anchored" data-anchor-id="read-dataset-in-pd.read_csv-and-display-first-several-rows.">Read dataset in pd.read_csv and display first several rows.</h5>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read dataset in pd.read_csv and display first several rows.</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"../data/01-modified-data/pytweetresult.csv"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="1">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Unnamed: 0</th>
      <th>text</th>
      <th>result</th>
      <th>scores</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>A more memorable connection is one that respec...</td>
      <td>Positive</td>
      <td>15.4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>A more memorable connection is one that respec...</td>
      <td>Positive</td>
      <td>15.4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>RT @OkeyMor57: @jay_scherrer @muskQu0tes @elon...</td>
      <td>Negative</td>
      <td>24.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>@jay_scherrer @muskQu0tes @elonmusk Elon Musk ...</td>
      <td>Negative</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>@DanKnightMMA Dear Dan - you seem like an enga...</td>
      <td>Positive</td>
      <td>26.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="print-shape-and-columns-of-the-dataset-and-describe-the-dataset" class="level5">
<h5 class="anchored" data-anchor-id="print-shape-and-columns-of-the-dataset-and-describe-the-dataset">Print shape and columns of the dataset and describe the dataset</h5>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print shape and columns of the dataset and describe the dataset</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.shape)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.columns)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.describe)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(1300, 4)
Index(['Unnamed: 0', 'text', 'result', 'scores'], dtype='object')
&lt;bound method NDFrame.describe of       Unnamed: 0                                               text    result  \
0              0  A more memorable connection is one that respec...  Positive   
1              1  A more memorable connection is one that respec...  Positive   
2              2  RT @OkeyMor57: @jay_scherrer @muskQu0tes @elon...  Negative   
3              3  @jay_scherrer @muskQu0tes @elonmusk Elon Musk ...  Negative   
4              4  @DanKnightMMA Dear Dan - you seem like an enga...  Positive   
...          ...                                                ...       ...   
1295        1295  When corporations write the rules, they only p...  Positive   
1296        1296  The American Data Privacy Protection Act (ADPP...  Positive   
1297        1297  Consumer privacy predictions—how marketers wil...  Negative   
1298        1298  To balance the advertisement benefits for busi...  Positive   
1299        1299  Consumer privacy predictions—how marketers wil...  Negative   

      scores  
0       15.4  
1       15.4  
2       24.2  
3       14.0  
4       26.0  
...      ...  
1295    11.6  
1296     9.5  
1297    15.1  
1298     6.9  
1299    13.8  

[1300 rows x 4 columns]&gt;</code></pre>
</div>
</div>
</section>
</section>
<section id="step-2-basic-data-exploration" class="level4">
<h4 class="anchored" data-anchor-id="step-2-basic-data-exploration">Step 2: Basic data exploration</h4>
<section id="insert-code-to-explore-the-load-balance-and-count-the-times-infl_score-0-and-infl_score-1" class="level5">
<h5 class="anchored" data-anchor-id="insert-code-to-explore-the-load-balance-and-count-the-times-infl_score-0-and-infl_score-1">Insert code to explore the load balance and count the times infl_score = 0 and infl_score = 1</h5>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Insert code to explore the load balance and count the times infl_score = 0 and infl_score = 1</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of points with result = Negative:"</span>,<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Negative'</span>),<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Negative'</span>)<span class="op">/</span>(<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Negative'</span>)<span class="op">+</span><span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Neutral'</span>)<span class="op">+</span><span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Positive'</span>)))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of points with result = Neutral:"</span>,<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Neutral'</span>),<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Neutral'</span>)<span class="op">/</span>(<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Negative'</span>)<span class="op">+</span><span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Neutral'</span>)<span class="op">+</span><span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Positive'</span>)))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of points with result = Neutral:"</span>,<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Positive'</span>),<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Positive'</span>)<span class="op">/</span>(<span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Negative'</span>)<span class="op">+</span><span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Neutral'</span>)<span class="op">+</span><span class="bu">sum</span>(df[<span class="st">'result'</span>]<span class="op">==</span><span class="st">'Positive'</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Number of points with result = Negative: 416 0.32
Number of points with result = Neutral: 286 0.22
Number of points with result = Neutral: 598 0.46</code></pre>
</div>
</div>
</section>
<section id="make-visulization-plot-of-eda" class="level5">
<h5 class="anchored" data-anchor-id="make-visulization-plot-of-eda">Make Visulization plot of EDA</h5>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'result'</span>].value_counts().plot(kind<span class="op">=</span><span class="st">"bar"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>&lt;AxesSubplot:&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="SVM_files/figure-html/cell-5-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>As we can see in the plot, Neutral is above 50% in the result of this dataset, the second more value is Postive, then is Negative</p>
</section>
<section id="drop-unnecessary-columns" class="level5">
<h5 class="anchored" data-anchor-id="drop-unnecessary-columns">Drop unnecessary columns</h5>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop([<span class="st">'Unnamed: 0'</span>,<span class="st">'scores'</span>],axis<span class="op">=</span><span class="dv">1</span>) <span class="co">#Drop unnecessary columns</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required packages</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> pos_tag</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> model_selection, naive_bayes, svm</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="data-preprocessing" class="level5">
<h5 class="anchored" data-anchor-id="data-preprocessing">Data preprocessing</h5>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># insert code to remove blank rows if any.</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'text'</span>].dropna()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Change all the text to lower case.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'text'</span>] <span class="op">=</span> [entry.lower() <span class="cf">for</span> entry <span class="kw">in</span> df[<span class="st">'text'</span>]]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenization In this each entry in the df will be broken into set of words</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'text'</span>] <span class="op">=</span> [word_tokenize(entry) <span class="cf">for</span> entry <span class="kw">in</span> df[<span class="st">'text'</span>]]</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>tag_map <span class="op">=</span> defaultdict(<span class="kw">lambda</span> : wn.NOUN)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>tag_map[<span class="st">'J'</span>] <span class="op">=</span> wn.ADJ</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>tag_map[<span class="st">'V'</span>] <span class="op">=</span> wn.VERB</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>tag_map[<span class="st">'R'</span>] <span class="op">=</span> wn.ADV</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index,entry <span class="kw">in</span> <span class="bu">enumerate</span>(df[<span class="st">'text'</span>]):</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Declaring Empty List to store the words that follow the rules for this step</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    Final_words <span class="op">=</span> []</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initializing WordNetLemmatizer()</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    word_Lemmatized <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, tag <span class="kw">in</span> pos_tag(entry):</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Below condition is to check for Stop words and consider only alphabets</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stopwords.words(<span class="st">'english'</span>) <span class="kw">and</span> word.isalpha():</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>            word_Final <span class="op">=</span> word_Lemmatized.lemmatize(word,tag_map[tag[<span class="dv">0</span>]])</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>            Final_words.append(word_Final)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The final processed set of words for each iteration will be stored in 'text_final'</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    df.loc[index,<span class="st">'text_final'</span>] <span class="op">=</span> <span class="bu">str</span>(Final_words)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>result</th>
      <th>text_final</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[a, more, memorable, connection, is, one, that...</td>
      <td>Positive</td>
      <td>['memorable', 'connection', 'one', 'respect', ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[a, more, memorable, connection, is, one, that...</td>
      <td>Positive</td>
      <td>['memorable', 'connection', 'one', 'respect', ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[rt, @, okeymor57, :, @, jay_scherrer, @, musk...</td>
      <td>Negative</td>
      <td>['rt', 'elonmusk', 'elon', 'musk', 'challenge'...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[@, jay_scherrer, @, muskqu0tes, @, elonmusk, ...</td>
      <td>Negative</td>
      <td>['elonmusk', 'elon', 'musk', 'challenge', 'don...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[@, danknightmma, dear, dan, -, you, seem, lik...</td>
      <td>Positive</td>
      <td>['danknightmma', 'dear', 'dan', 'seem', 'like'...</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="drop-initial-text-column" class="level5">
<h5 class="anchored" data-anchor-id="drop-initial-text-column">Drop initial text column</h5>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop([<span class="st">'text'</span>],axis<span class="op">=</span><span class="dv">1</span>) <span class="co"># Drop Initial text column</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>result</th>
      <th>text_final</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Positive</td>
      <td>['memorable', 'connection', 'one', 'respect', ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Positive</td>
      <td>['memorable', 'connection', 'one', 'respect', ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Negative</td>
      <td>['rt', 'elonmusk', 'elon', 'musk', 'challenge'...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Negative</td>
      <td>['elonmusk', 'elon', 'musk', 'challenge', 'don...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Positive</td>
      <td>['danknightmma', 'dear', 'dan', 'seem', 'like'...</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="step-3-split-dataset" class="level4">
<h4 class="anchored" data-anchor-id="step-3-split-dataset">Step 3 Split dataset</h4>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Insert code to partition datasets into training and testing datasets and print types and shapes of these datasets</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>x_train,x_test,y_train,y_test<span class="op">=</span>train_test_split(df[<span class="st">'text_final'</span>],df[<span class="st">'result'</span>],test_size<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(x_train),x_train.shape)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(y_train),y_train.shape)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(x_test),x_test.shape)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(y_test),y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.series.Series'&gt; (260,)
&lt;class 'pandas.core.series.Series'&gt; (260,)
&lt;class 'pandas.core.series.Series'&gt; (1040,)
&lt;class 'pandas.core.series.Series'&gt; (1040,)</code></pre>
</div>
</div>
<p>Insert code to encode the column infl_score with value between 0 and 1 and 2. 0 represents Negative, 1 represents Neutral, 2 represnets Positive</p>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Insert code to encode the column infl_score with value between 0 and 1 and 2. 0 represents Negative, 1 represents Neutral, 2 represnets Positive</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>Encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> Encoder.fit_transform(y_train)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> Encoder.fit_transform(y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>Word Vectorization</p>
<p>One sentence summarizes the use of word vectors: it provides a mathematical method to convert symbolic information such as natural language into digital information in the form of vectors. This transforms natural language problems into machine learning problems.</p>
<p>The most commonly used word vector models are nothing more than one-hot Representation model and distributed representation model.</p>
<p>One-hot Representation One-hot Representation uses a very long vector to represent a word. The length of the vector is the size N of the dictionary. Each vector has only one dimension which is 1, indicating the position of the word in the dictionary, and all other dimensions are 0.</p>
<p>Example:</p>
<p>“Mic” is expressed as [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 …] “Mike” is expressed as [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 …]</p>
<p>If this One-hot Representation is stored in a sparse manner, it will be very concise, that is, assign a digital ID to each word. But this representation has two disadvantages:</p>
<ol type="1">
<li>Suffering from the curse of dimensionality, the dimension of each word is the length of the corpus dictionary.</li>
<li>Word encoding is often random, resulting in the inability to describe the similarity between words</li>
</ol>
<p>Distributed representation Distributed representation was first proposed by Hinton in 1986. It relies on the idea that the semantics of words is determined by contextual information, that is, words appearing in the same context have similar semantics.</p>
<p>Distributed representation Distributed representation was first proposed by Hinton in 1986. It relies on the idea that the semantics of words is determined by contextual information, that is, words appearing in the same context have similar semantics.</p>
<p>Distributed Representation vs.&nbsp;one-hot representation</p>
<p>Formally, the one-hot representation word vector is a sparse word vector whose length is the length of the dictionary, while the Distributed Representation is a fixed-length dense word vector. Generally it looks like this: [0.792, −0.177, −0.107, 0.109, −0.542, …] Functionally, the biggest contribution of Distributed representation is to make related or similar words closer in distance.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>Tfidf_vect <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>Tfidf_vect.fit(df[<span class="st">'text_final'</span>])</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>Train_X_Tfidf <span class="op">=</span> Tfidf_vect.transform(x_train)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>Test_X_Tfidf <span class="op">=</span> Tfidf_vect.transform(x_test)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Train_X_Tfidf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  (0, 431)  0.39343054767211405
  (0, 422)  0.39343054767211405
  (0, 421)  0.21270247409445098
  (0, 379)  0.10777508549892469
  (0, 324)  0.41978781772324697
  (0, 289)  0.39343054767211405
  (0, 241)  0.39343054767211405
  (0, 240)  0.13991072862375892
  (0, 230)  0.34177701917836245
  (0, 108)  0.1066932535925145
  (1, 421)  0.17578173050759396
  (1, 379)  0.08906756310785721
  (1, 339)  0.34692134804521224
  (1, 246)  0.3773440588795487
  (1, 206)  0.3773440588795487
  (1, 184)  0.42818082446664624
  (1, 129)  0.19797855636694156
  (1, 108)  0.08817351481134954
  (1, 93)   0.3773440588795487
  (1, 8)    0.42818082446664624
  (2, 379)  0.24765096259824637
  (2, 301)  0.622577221818474
  (2, 240)  0.3214938449001891
  (2, 108)  0.24516507532892332
  (2, 18)   0.622577221818474
  : :
  (256, 156)    0.2365071214185549
  (256, 134)    0.2365071214185549
  (256, 108)    0.09740587612424956
  (256, 27) 0.14537183151680322
  (256, 11) 0.2365071214185549
  (256, 3)  0.14090351047368133
  (257, 379)    0.21636746718506106
  (257, 301)    0.5439326994682515
  (257, 240)    0.5617648985236235
  (257, 108)    0.21419559946232755
  (257, 18) 0.5439326994682515
  (258, 379)    0.7106645633449062
  (258, 108)    0.7035310074231227
  (259, 529)    0.34038255559099734
  (259, 476)    0.26542161561958894
  (259, 461)    0.34038255559099734
  (259, 421)    0.15856360594107566
  (259, 401)    0.3129398019074078
  (259, 379)    0.08034324123436727
  (259, 252)    0.3862397720525404
  (259, 206)    0.34038255559099734
  (259, 129)    0.17858621431192803
  (259, 108)    0.07953676651500724
  (259, 66) 0.3862397720525404
  (259, 47) 0.34038255559099734</code></pre>
</div>
</div>
<p>Now the column text is ready to be fed into SVM algortithms.</p>
</section>
<section id="step-4-training-and-predicting-the-model" class="level4">
<h4 class="anchored" data-anchor-id="step-4-training-and-predicting-the-model">Step 4 Training and Predicting the model</h4>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classifier - Algorithm - SVM</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the training dataset on the classifier</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>SVC <span class="op">=</span> svm.SVC()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC.fit(Train_X_Tfidf,y_train)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># predict the labels on validation dataset</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> model.predict(Train_X_Tfidf)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> model.predict(Test_X_Tfidf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"confusion matrix of train data:"</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_train,yp_train))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" "</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"confusion matrix of test data:"</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test,yp_test))</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" "</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"classification report of train data:"</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_train,yp_train))</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" "</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"classification report of test data:"</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test,yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>confusion matrix of train data:
[[ 81   0   0]
 [  0  49   0]
 [  0   0 130]]
 
confusion matrix of test data:
[[322   0  13]
 [  0 237   0]
 [  0   0 468]]
 
classification report of train data:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        81
           1       1.00      1.00      1.00        49
           2       1.00      1.00      1.00       130

    accuracy                           1.00       260
   macro avg       1.00      1.00      1.00       260
weighted avg       1.00      1.00      1.00       260

 
classification report of test data:
              precision    recall  f1-score   support

           0       1.00      0.96      0.98       335
           1       1.00      1.00      1.00       237
           2       0.97      1.00      0.99       468

    accuracy                           0.99      1040
   macro avg       0.99      0.99      0.99      1040
weighted avg       0.99      0.99      0.99      1040
</code></pre>
</div>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the results in a data frame. </span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>dic_train <span class="op">=</span> classification_report(y_train,yp_train,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>dic_test <span class="op">=</span> classification_report(y_test,yp_test,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> pd.DataFrame.from_dict(dic_train)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> result_train.transpose()</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> pd.DataFrame.from_dict(dic_test)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> result_test.transpose()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>display the results data frame</p>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># display the results data frame</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of train dataset:"</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_train)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of test dataset:"</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>result dataframe of train dataset:
              precision  recall  f1-score  support
0                   1.0     1.0       1.0     81.0
1                   1.0     1.0       1.0     49.0
2                   1.0     1.0       1.0    130.0
accuracy            1.0     1.0       1.0      1.0
macro avg           1.0     1.0       1.0    260.0
weighted avg        1.0     1.0       1.0    260.0

result dataframe of test dataset:
              precision    recall  f1-score    support
0              1.000000  0.961194  0.980213   335.0000
1              1.000000  1.000000  1.000000   237.0000
2              0.972973  1.000000  0.986301   468.0000
accuracy       0.987500  0.987500  0.987500     0.9875
macro avg      0.990991  0.987065  0.988838  1040.0000
weighted avg   0.987838  0.987500  0.987462  1040.0000</code></pre>
</div>
</div>
<p>Display Confusion Matrix for the test data. Remember to use the ConfusionMatrixDisplay function.</p>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Confusion Matrix for the test data. Remember to use the ConfusionMatrixDisplay function.</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_test, yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fadb1296ad0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="SVM_files/figure-html/cell-17-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Comment: As we can see, the precision, recall, f1-score and support of accuracy are all about 96%, which we can conclude SVM is a good model to predict the sentiment analysis of this text dataset.</p>
<section id="tuning-hyperparameters" class="level5">
<h5 class="anchored" data-anchor-id="tuning-hyperparameters">Tuning Hyperparameters</h5>
<p>Kernel: Kernel methods kernel methods (KMs) are a class of pattern recognition algorithms. Its purpose is to find and learn the mutual relationship in a set of data. Widely used kernel methods include support vector machines, Gaussian processes, etc. The kernel method is an effective way to solve the problem of nonlinear pattern analysis. Its core idea is: first, the original data is embedded into a suitable high-dimensional feature space through some nonlinear mapping; then, the general linear learner is used in this New in-space analysis and processing modes. Kernel methods have distinct advantages over the paradigm of using general-purpose nonlinear learners to analyze directly on raw data: First of all, the general nonlinear learner is inconvenient to reflect the characteristics of specific application problems, while the nonlinear mapping of the kernel method is designed for specific application problems, which is convenient for integrating prior knowledge related to the problem. Furthermore, linear learners have better overfitting control than nonlinear learners, which can better guarantee generalization performance. Also, it is very important that the kernel method is still a way to achieve efficient calculations. It can use the kernel function to implicitly nonlinear mapping in the linear learner for simultaneous calculations, so that the computational complexity has nothing to do with the dimensionality of the high-dimensional feature space.</p>
<p>In this dataset, I will train different kernels(‘poly’,‘RBF’ and ‘Linear’) to determine which suports the most accurate classifers.</p>
</section>
<section id="svm-with-polynomial-kernels" class="level5">
<h5 class="anchored" data-anchor-id="svm-with-polynomial-kernels">SVM with Polynomial kernels</h5>
<p>A polynomial kernel is a more generalized form of the linear kernel. The polynomial kernel can distinguish curved or nonlinear input space.</p>
<p>K(x,xi) = 1 + sum(x * xi)^d</p>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>SVC <span class="op">=</span> svm.SVC(C <span class="op">=</span> <span class="fl">0.5</span>,degree <span class="op">=</span> <span class="dv">2</span>,kernel<span class="op">=</span><span class="st">'poly'</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC.fit(Train_X_Tfidf, y_train)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> SVC.predict(Train_X_Tfidf)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> SVC.predict(Test_X_Tfidf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>Calculate the confusion matrix and classification report for the train and test data.</p>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the confusion matrix and classification report for the train and test data. </span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"confusion matrix of train data:"</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_train,yp_train))</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" "</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"confusion matrix of test data:"</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test,yp_test))</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" "</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"classification report of train data:"</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_train,yp_train))</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" "</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"classification reportof test data:"</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test,yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>confusion matrix of train data:
[[ 80   0   1]
 [  0  49   0]
 [  0   0 130]]
 
confusion matrix of test data:
[[310   0  25]
 [  0 224  13]
 [  0   0 468]]
 
classification report of train data:
              precision    recall  f1-score   support

           0       1.00      0.99      0.99        81
           1       1.00      1.00      1.00        49
           2       0.99      1.00      1.00       130

    accuracy                           1.00       260
   macro avg       1.00      1.00      1.00       260
weighted avg       1.00      1.00      1.00       260

 
classification reportof test data:
              precision    recall  f1-score   support

           0       1.00      0.93      0.96       335
           1       1.00      0.95      0.97       237
           2       0.92      1.00      0.96       468

    accuracy                           0.96      1040
   macro avg       0.97      0.96      0.96      1040
weighted avg       0.97      0.96      0.96      1040
</code></pre>
</div>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the results in a data frame.</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>dic_train <span class="op">=</span> classification_report(y_train,yp_train,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>dic_test <span class="op">=</span> classification_report(y_test,yp_test,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> pd.DataFrame.from_dict(dic_train)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> result_train.transpose()</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> pd.DataFrame.from_dict(dic_test)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> result_test.transpose()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>display the results data frame</p>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># display the results data frame</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of train dataset:"</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_train)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of test dataset:"</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>result dataframe of train dataset:
              precision    recall  f1-score     support
0              1.000000  0.987654  0.993789   81.000000
1              1.000000  1.000000  1.000000   49.000000
2              0.992366  1.000000  0.996169  130.000000
accuracy       0.996154  0.996154  0.996154    0.996154
macro avg      0.997455  0.995885  0.996652  260.000000
weighted avg   0.996183  0.996154  0.996149  260.000000

result dataframe of test dataset:
              precision    recall  f1-score      support
0              1.000000  0.925373  0.961240   335.000000
1              1.000000  0.945148  0.971800   237.000000
2              0.924901  1.000000  0.960986   468.000000
accuracy       0.963462  0.963462  0.963462     0.963462
macro avg      0.974967  0.956840  0.964675  1040.000000
weighted avg   0.966206  0.963462  0.963532  1040.000000</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Confusion Matrix for the test data. Remember to use the ConfusionMatrixDisplay function.</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_test, yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fada217a4a0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="SVM_files/figure-html/cell-22-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="svm-with-rbf-kernels" class="level5">
<h5 class="anchored" data-anchor-id="svm-with-rbf-kernels">SVM with RBF kernels</h5>
<p>Radial Basis Function Kernel The Radial basis function kernel is a popular kernel function commonly used in support vector machine classification. RBF can map an input space in infinite dimensional space.</p>
<p>K(x,xi) = exp(-gamma * sum((x – xi^2))</p>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>SVC <span class="op">=</span> svm.SVC(C <span class="op">=</span> <span class="fl">0.5</span>,kernel<span class="op">=</span><span class="st">'rbf'</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC.fit(Train_X_Tfidf, y_train)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> SVC.predict(Train_X_Tfidf)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> SVC.predict(Test_X_Tfidf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>display the results data frame</p>
<div class="cell" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the results in a data frame.</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>dic_train <span class="op">=</span> classification_report(y_train,yp_train,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>dic_test <span class="op">=</span> classification_report(y_test,yp_test,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> pd.DataFrame.from_dict(dic_train)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> result_train.transpose()</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> pd.DataFrame.from_dict(dic_test)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> result_test.transpose()</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># display the results data frame</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of train dataset:"</span>)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_train)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of test dataset:"</span>)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>result dataframe of train dataset:
              precision    recall  f1-score     support
0              1.000000  0.975309  0.987500   81.000000
1              1.000000  0.938776  0.968421   49.000000
2              0.962963  1.000000  0.981132  130.000000
accuracy       0.980769  0.980769  0.980769    0.980769
macro avg      0.987654  0.971361  0.979018  260.000000
weighted avg   0.981481  0.980769  0.980720  260.000000

result dataframe of test dataset:
              precision    recall  f1-score      support
0              1.000000  0.889552  0.941548   335.000000
1              1.000000  0.793249  0.884706   237.000000
2              0.844765  1.000000  0.915851   468.000000
accuracy       0.917308  0.917308  0.917308     0.917308
macro avg      0.948255  0.894267  0.914035  1040.000000
weighted avg   0.930144  0.917308  0.917031  1040.000000</code></pre>
</div>
</div>
<p>Display Confusion Matrix for the test data. Remember to use the ConfusionMatrixDisplay function.</p>
<div class="cell" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Confusion Matrix for the test data. Remember to use the ConfusionMatrixDisplay function.</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_test, yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fadb3b38d60&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="SVM_files/figure-html/cell-25-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="svm-with-linear-kernels" class="level5">
<h5 class="anchored" data-anchor-id="svm-with-linear-kernels">SVM with Linear Kernels</h5>
<p>A linear kernel can be used as normal dot product any two given observations. The product between two vectors is the sum of the multiplication of each pair of input values.</p>
<p>K(x, xi) = sum(x * xi)</p>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>SVC <span class="op">=</span> svm.SVC(C<span class="op">=</span><span class="fl">1.0</span>, kernel<span class="op">=</span><span class="st">'linear'</span>, degree<span class="op">=</span><span class="dv">3</span>, gamma<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC.fit(Train_X_Tfidf, y_train)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> SVC.predict(Train_X_Tfidf)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> SVC.predict(Test_X_Tfidf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell" data-execution_count="26">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the results in a data frame.</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>dic_train <span class="op">=</span> classification_report(y_train,yp_train,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>dic_test <span class="op">=</span> classification_report(y_test,yp_test,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> pd.DataFrame.from_dict(dic_train)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>result_train <span class="op">=</span> result_train.transpose()</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> pd.DataFrame.from_dict(dic_test)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>result_test <span class="op">=</span> result_test.transpose()</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># display the results data frame</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of train dataset:"</span>)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_train)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"result dataframe of test dataset:"</span>)</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>result dataframe of train dataset:
              precision  recall  f1-score  support
0                   1.0     1.0       1.0     81.0
1                   1.0     1.0       1.0     49.0
2                   1.0     1.0       1.0    130.0
accuracy            1.0     1.0       1.0      1.0
macro avg           1.0     1.0       1.0    260.0
weighted avg        1.0     1.0       1.0    260.0

result dataframe of test dataset:
              precision    recall  f1-score    support
0              1.000000  0.961194  0.980213   335.0000
1              1.000000  1.000000  1.000000   237.0000
2              0.972973  1.000000  0.986301   468.0000
accuracy       0.987500  0.987500  0.987500     0.9875
macro avg      0.990991  0.987065  0.988838  1040.0000
weighted avg   0.987838  0.987500  0.987462  1040.0000</code></pre>
</div>
</div>
<p>Display Confusion Matrix for the test data. Remember to use the ConfusionMatrixDisplay function.</p>
<div class="cell" data-execution_count="27">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Confusion Matrix for the test data. Remember to use the ConfusionMatrixDisplay function.</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_test, yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fadb3b67f70&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="SVM_files/figure-html/cell-28-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Comment: From the comparisons above from these three kernels, the linear permance best with showing the higher accuracy score of test which is almost 99%. The error made becomes smaller.</p>
</section>
</section>
<section id="conclusion" class="level4">
<h4 class="anchored" data-anchor-id="conclusion">Conclusion</h4>
<p>From the above three kernels training performance, we can conclude that linear kernel is the most suitable kernel from above three kernels(poly, rbf, linear). The accuracy score is almost 96%. By using the the hyperparameter tunning, the accuracy is higher and the model becomes a more accurate classifier.</p>
<p>SVM Classifiers offer good accuracy and perform faster prediction compared to Naïve Bayes algorithm. They also use less memory because they use a subset of training points in the decision phase. SVM works well with a clear margin of separation and with high dimensional space. However, SVM is not suitable for large datasets because of its high training time and it also takes more time in training compared to Naïve Bayes. It works poorly with overlapping classes and is also sensitive to the type of kernel used.</p>
<p>Overall, I think SVM is a suitable model to predict sentiment analysis of text data about consumer privacy.</p>
</section>
<section id="reference" class="level4">
<h4 class="anchored" data-anchor-id="reference">Reference</h4>
<p>Wikimedia Foundation. (2022, December 2). Support Vector Machine. Wikipedia. Retrieved December 3, 2022, from https://en.wikipedia.org/wiki/Support_vector_machine</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>